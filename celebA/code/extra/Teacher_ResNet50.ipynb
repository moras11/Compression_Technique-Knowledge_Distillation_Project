{"cells":[{"cell_type":"code","execution_count":null,"id":"5c581f2d-fb3b-484a-a4bf-30e029211096","metadata":{"id":"5c581f2d-fb3b-484a-a4bf-30e029211096","outputId":"874e22a6-05eb-4340-cd00-58ca1d96822e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in c:\\users\\akash\\anaconda3\\lib\\site-packages (2.6.0+cu118)\n","Requirement already satisfied: torchvision in c:\\users\\akash\\anaconda3\\lib\\site-packages (0.21.0)\n","Requirement already satisfied: pandas in c:\\users\\akash\\anaconda3\\lib\\site-packages (2.2.1)\n","Requirement already satisfied: matplotlib in c:\\users\\akash\\anaconda3\\lib\\site-packages (3.9.2)\n","Requirement already satisfied: pillow in c:\\users\\akash\\anaconda3\\lib\\site-packages (10.3.0)\n","Requirement already satisfied: filelock in c:\\users\\akash\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n","Requirement already satisfied: networkx in c:\\users\\akash\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in c:\\users\\akash\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n","Requirement already satisfied: setuptools in c:\\users\\akash\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n","Requirement already satisfied: sympy==1.13.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in c:\\users\\akash\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: six>=1.5 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n","Using device: cuda\n"]}],"source":["# Install requirements (if needed)\n","!pip install torch torchvision pandas matplotlib pillow\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torchvision import transforms, models\n","from torchvision.models import ResNet50_Weights\n","import pandas as pd\n","from PIL import Image\n","from tqdm.auto import tqdm\n","import matplotlib.pyplot as plt\n","import time\n","from torchvision import models\n","from torch.utils.data import DataLoader\n","import numpy as np\n","from typing import Dict, Tuple, List\n","import datetime\n","\n","\n","# Configuration\n","class Config:\n","    root_dir = 'D:/celeba/img_align_celeba/img_align_celeba'\n","    csv_path = 'D:/celeba/list_attr_celeba.csv'\n","\n","    num_classes = 40\n","    batch_size = 64\n","    lr = 1e-3\n","    patience = 3\n","    train_ratio = 0.8\n","    image_size = 224\n","    mean = [0.485, 0.456, 0.406]\n","    std = [0.229, 0.224, 0.225]\n","\n","    pretrained_weights = models.ResNet50_Weights.IMAGENET1K_V2\n","    max_epochs = 10\n","    grad_clip = 1.0\n","    grad_accum_steps = 2\n","    log_interval = 10\n","    early_stop_patience = 5\n","    attribute_names = [f\"Attr_{i}\" for i in range(40)]  # Replace with actual names\n","\n","# Dataset class\n","class CelebADataset(Dataset):\n","    def __init__(self, root_dir, csv_path, transform=None):\n","        self.df = pd.read_csv(csv_path)\n","        self.df.iloc[:, 1:] = self.df.iloc[:, 1:].replace(-1, 0)\n","        self.root_dir = root_dir\n","        self.transform = transform or transforms.Compose([\n","            transforms.Resize(256),\n","            transforms.RandomCrop(224),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            transforms.Normalize(Config.mean, Config.std)\n","        ])\n","        self.image_names = self.df['image_id']\n","        self.labels = self.df.drop('image_id', axis=1).values.astype('float32')\n","\n","    def __len__(self): return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.root_dir, self.image_names[idx])\n","        try:\n","            image = Image.open(img_path).convert('RGB')\n","            if self.transform:\n","                image = self.transform(image)\n","        except Exception as e:\n","            print(f\"Error loading {img_path}: {str(e)}\")\n","            # Return zero image and corresponding label\n","            image = torch.zeros(3, 224, 224)\n","            return image, self.labels[idx]\n","\n","        return image, self.labels[idx]  # Fixed the label reference here\n","\n","# Initialize device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Load dataset\n","dataset = CelebADataset(Config.root_dir, Config.csv_path)\n","train_size = int(len(dataset) * Config.train_ratio)\n","train_set, val_set = random_split(dataset, [train_size, len(dataset)-train_size])\n","\n","    # Data loader configuration\n","train_loader = DataLoader(\n","        train_set,\n","        batch_size=Config.batch_size,\n","        shuffle=True,\n","        num_workers=0,  # Critical for Windows/Jupyter stability\n","        pin_memory=True,\n","        persistent_workers=False\n","    )\n","\n","val_loader = DataLoader(\n","        val_set,\n","        batch_size=Config.batch_size,\n","        num_workers=0,\n","        pin_memory=True\n","    )"]},{"cell_type":"code","execution_count":null,"id":"c86661d0-4c0f-42c8-9881-a995e4472224","metadata":{"id":"c86661d0-4c0f-42c8-9881-a995e4472224","outputId":"b01d34dd-86af-4121-c3c9-0fcb91f3eb3a"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_28732\\1565594552.py:64: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler()\n","C:\\Users\\akash\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n","C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_28732\\1565594552.py:83: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 Batch 2530/2533 Loss: 0.0964\n","Epoch 1/10 Summary:\n","Start Time: 02:36:36 | Duration: 1:00:48 | Total Elapsed: 1:00:48\n","Learning Rate: 1.00e-03\n","Train Loss: 0.0000 | Val Loss: 0.1985\n","Train Acc: 0.9101 | Val Acc: 0.9127\n","Train F1: 0.6866 | Val F1: 0.6896\n","Train Precision: 0.7505 | Val Precision: 0.7633\n","Train Recall: 0.6536 | Val Recall: 0.6528\n","Epoch 2 Batch 2530/2533 Loss: 0.1018\n","Epoch 2/10 Summary:\n","Start Time: 03:37:24 | Duration: 0:53:04 | Total Elapsed: 1:53:52\n","Learning Rate: 1.00e-03\n","Train Loss: 0.0000 | Val Loss: 0.1938\n","Train Acc: 0.9138 | Val Acc: 0.9147\n","Train F1: 0.6962 | Val F1: 0.6959\n","Train Precision: 0.7769 | Val Precision: 0.7840\n","Train Recall: 0.6522 | Val Recall: 0.6496\n","Epoch 3 Batch 2530/2533 Loss: 0.0965\n","Epoch 3/10 Summary:\n","Start Time: 04:30:29 | Duration: 0:57:07 | Total Elapsed: 2:51:00\n","Learning Rate: 1.00e-03\n","Train Loss: 0.0000 | Val Loss: 0.1900\n","Train Acc: 0.9158 | Val Acc: 0.9163\n","Train F1: 0.7043 | Val F1: 0.7024\n","Train Precision: 0.7837 | Val Precision: 0.7869\n","Train Recall: 0.6607 | Val Recall: 0.6576\n","Epoch 4 Batch 2530/2533 Loss: 0.0856\n","Epoch 4/10 Summary:\n","Start Time: 05:27:36 | Duration: 0:53:42 | Total Elapsed: 3:44:43\n","Learning Rate: 1.00e-03\n","Train Loss: 0.0000 | Val Loss: 0.1878\n","Train Acc: 0.9174 | Val Acc: 0.9170\n","Train F1: 0.7072 | Val F1: 0.7044\n","Train Precision: 0.7917 | Val Precision: 0.7901\n","Train Recall: 0.6598 | Val Recall: 0.6572\n","Epoch 5 Batch 2530/2533 Loss: 0.0910\n","Epoch 5/10 Summary:\n","Start Time: 06:21:19 | Duration: 0:43:02 | Total Elapsed: 4:27:46\n","Learning Rate: 1.00e-03\n","Train Loss: 0.0000 | Val Loss: 0.1870\n","Train Acc: 0.9183 | Val Acc: 0.9174\n","Train F1: 0.7197 | Val F1: 0.7130\n","Train Precision: 0.7864 | Val Precision: 0.7846\n","Train Recall: 0.6815 | Val Recall: 0.6728\n","Epoch 6 Batch 2530/2533 Loss: 0.0916\n","Epoch 6/10 Summary:\n","Start Time: 07:04:22 | Duration: 0:35:24 | Total Elapsed: 5:03:10\n","Learning Rate: 1.00e-03\n","Train Loss: 0.0000 | Val Loss: 0.1858\n","Train Acc: 0.9196 | Val Acc: 0.9180\n","Train F1: 0.7178 | Val F1: 0.7089\n","Train Precision: 0.7988 | Val Precision: 0.7946\n","Train Recall: 0.6734 | Val Recall: 0.6628\n","Epoch 7 Batch 2530/2533 Loss: 0.0930\n","Epoch 7/10 Summary:\n","Start Time: 07:39:47 | Duration: 0:34:30 | Total Elapsed: 5:37:41\n","Learning Rate: 1.00e-03\n","Train Loss: 0.0000 | Val Loss: 0.1858\n","Train Acc: 0.9203 | Val Acc: 0.9179\n","Train F1: 0.7278 | Val F1: 0.7161\n","Train Precision: 0.7931 | Val Precision: 0.7859\n","Train Recall: 0.6873 | Val Recall: 0.6740\n","Epoch 8 Batch 2530/2533 Loss: 0.0942\n","Epoch 8/10 Summary:\n","Start Time: 08:14:17 | Duration: 0:34:30 | Total Elapsed: 6:12:12\n","Learning Rate: 1.00e-03\n","Train Loss: 0.0000 | Val Loss: 0.1858\n","Train Acc: 0.9208 | Val Acc: 0.9177\n","Train F1: 0.7285 | Val F1: 0.7138\n","Train Precision: 0.7953 | Val Precision: 0.7845\n","Train Recall: 0.6926 | Val Recall: 0.6772\n","Epoch 9 Batch 2530/2533 Loss: 0.0872\n","Epoch 9/10 Summary:\n","Start Time: 08:48:48 | Duration: 0:34:30 | Total Elapsed: 6:46:43\n","Learning Rate: 1.00e-03\n","Train Loss: 0.0000 | Val Loss: 0.1839\n","Train Acc: 0.9224 | Val Acc: 0.9188\n","Train F1: 0.7416 | Val F1: 0.7254\n","Train Precision: 0.7929 | Val Precision: 0.7811\n","Train Recall: 0.7097 | Val Recall: 0.6917\n","Epoch 10 Batch 2530/2533 Loss: 0.0890\n","Epoch 10/10 Summary:\n","Start Time: 09:23:19 | Duration: 0:34:34 | Total Elapsed: 7:21:18\n","Learning Rate: 1.00e-03\n","Train Loss: 0.0000 | Val Loss: 0.1843\n","Train Acc: 0.9231 | Val Acc: 0.9185\n","Train F1: 0.7365 | Val F1: 0.7154\n","Train Precision: 0.8115 | Val Precision: 0.7952\n","Train Recall: 0.6926 | Val Recall: 0.6702\n"]},{"ename":"AttributeError","evalue":"'AttributeClassifier' object has no attribute '_print_final_metrics'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[20], line 262\u001b[0m\n\u001b[0;32m    259\u001b[0m config \u001b[38;5;241m=\u001b[39m Config()\n\u001b[0;32m    260\u001b[0m classifier \u001b[38;5;241m=\u001b[39m AttributeClassifier(config)\n\u001b[1;32m--> 262\u001b[0m history \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mtrain(train_loader, val_loader)\n\u001b[0;32m    263\u001b[0m classifier\u001b[38;5;241m.\u001b[39mgenerate_visualizations()\n","Cell \u001b[1;32mIn[20], line 144\u001b[0m, in \u001b[0;36mAttributeClassifier.train\u001b[1;34m(self, train_loader, val_loader)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Final model evaluation\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_final_metrics(val_loader)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\n","\u001b[1;31mAttributeError\u001b[0m: 'AttributeClassifier' object has no attribute '_print_final_metrics'"]}],"source":["class AttributeClassifier:\n","    def __init__(self, config):\n","        self.config = config\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.model = self._build_model()\n","        self.optimizer = self._configure_optimizer()\n","        self.criterion = nn.BCEWithLogitsLoss()\n","        self._init_history()\n","\n","    def _init_history(self):\n","        self.history = {\n","            'train_loss': [], 'val_loss': [],\n","            'train_acc': [], 'val_acc': [],\n","            'train_f1': [], 'val_f1': [],\n","            'train_precision': [], 'val_precision': [],\n","            'train_recall': [], 'val_recall': [],\n","            'train_attr_metrics': {i: {'acc': [], 'f1': [], 'precision': [], 'recall': []}\n","                                 for i in range(self.config.num_classes)},\n","            'val_attr_metrics': {i: {'acc': [], 'f1': [], 'precision': [], 'recall': []}\n","                               for i in range(self.config.num_classes)},\n","            'learning_rates': []\n","        }\n","\n","    def _build_model(self) -> nn.Module:\n","        # Load pretrained ResNet50\n","        model = models.resnet50(weights=self.config.pretrained_weights)\n","\n","        # Freeze all layers except final blocks\n","        for param in model.parameters():\n","            param.requires_grad = False\n","\n","        # Unfreeze layer4 and classifier\n","        for param in model.layer3.parameters():\n","            param.requires_grad = True\n","\n","        for param in model.layer4.parameters():\n","            param.requires_grad = True\n","\n","        # Replace final fully connected layer\n","        model.fc = nn.Sequential(\n","            nn.Linear(model.fc.in_features, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(512, self.config.num_classes)\n","        )\n","\n","        # Initialize classifier weights\n","        for layer in model.fc:\n","            if isinstance(layer, nn.Linear):\n","                nn.init.kaiming_normal_(layer.weight)\n","                nn.init.constant_(layer.bias, 0)\n","\n","        return model.to(self.device)\n","\n","    def _configure_optimizer(self) -> optim.Optimizer:\n","        # Only optimize unfrozen parameters\n","        return optim.AdamW(\n","            filter(lambda p: p.requires_grad, self.model.parameters()),\n","            lr=self.config.lr,\n","            weight_decay=0.01\n","        )\n","\n","    def train(self, train_loader: DataLoader, val_loader: DataLoader) -> Dict:\n","        scaler = torch.cuda.amp.GradScaler()\n","        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","            self.optimizer, 'max', patience=3, factor=0.5, verbose=True\n","        )\n","        best_f1 = 0\n","        epochs_no_improve = 0\n","        start_train_time = time.time()  # Track total training start time\n","\n","        for epoch in range(self.config.max_epochs):\n","            epoch_start_time = time.time()\n","            epoch_start_str = time.strftime(\"%H:%M:%S\")  # Human-readable start time\n","\n","            # Training Phase\n","            self.model.train()\n","            epoch_loss = 0\n","            for batch_idx, (inputs, labels) in enumerate(train_loader):\n","                inputs, labels = inputs.to(self.device), labels.to(self.device)\n","\n","                # Forward pass with mixed precision\n","                with torch.cuda.amp.autocast():\n","                    outputs = self.model(inputs)\n","                    loss = self.criterion(outputs, labels) / self.config.grad_accum_steps\n","\n","                # Backward pass and gradient accumulation\n","                scaler.scale(loss).backward()\n","\n","                if (batch_idx + 1) % self.config.grad_accum_steps == 0:\n","                    scaler.unscale_(self.optimizer)\n","                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.grad_clip)\n","                    scaler.step(self.optimizer)\n","                    scaler.update()\n","                    self.optimizer.zero_grad()\n","\n","                epoch_loss += loss.item() * self.config.grad_accum_steps\n","\n","                # Batch progress logging\n","                if batch_idx % self.config.log_interval == 0:\n","                    print(f'\\rEpoch {epoch+1} Batch {batch_idx}/{len(train_loader)} '\n","                          f'Loss: {loss.item():.4f}', end='')\n","\n","            # Calculate training loss and store\n","            train_loss = epoch_loss / len(train_loader)\n","            self.history['train_loss'].append(train_loss)\n","\n","            # Validation Phase\n","            train_metrics = self._compute_epoch_metrics(train_loader, 'train')\n","            val_metrics = self._compute_epoch_metrics(val_loader, 'val')\n","\n","            # Learning rate scheduling\n","            current_lr = self.optimizer.param_groups[0]['lr']\n","            self.history['learning_rates'].append(current_lr)\n","            scheduler.step(val_metrics['f1'])\n","\n","            # Calculate time metrics\n","            epoch_duration = time.time() - epoch_start_time\n","            total_duration = time.time() - start_train_time\n","\n","            # Print epoch summary with new details\n","            self._print_epoch_summary(\n","                epoch=epoch,\n","                train_metrics=train_metrics,\n","                val_metrics=val_metrics,\n","                epoch_start_str=epoch_start_str,\n","                epoch_duration=epoch_duration,\n","                total_duration=total_duration\n","            )\n","\n","            # Early stopping check\n","            if val_metrics['f1'] > best_f1:\n","                best_f1 = val_metrics['f1']\n","                epochs_no_improve = 0\n","                torch.save(self.model.state_dict(), 'best_model.pth')\n","            else:\n","                epochs_no_improve += 1\n","                if epochs_no_improve >= self.config.early_stop_patience:\n","                    print(f\"\\nEarly stopping triggered after {epoch+1} epochs!\")\n","                    break\n","\n","        # Final model evaluation\n","        self.model.load_state_dict(torch.load('best_model.pth'))\n","        self._print_final_metrics(val_loader)\n","        return self.history\n","\n","    def _print_epoch_summary(self, epoch: int, train_metrics: Dict,\n","                           val_metrics: Dict, epoch_start_str: str,\n","                           epoch_duration: float, total_duration: float):\n","        \"\"\"Enhanced epoch summary with time metrics and learning rate\"\"\"\n","        # Format time durations\n","        epoch_time = str(datetime.timedelta(seconds=int(epoch_duration)))\n","        total_time = str(datetime.timedelta(seconds=int(total_duration)))\n","\n","        # Get current learning rate\n","        current_lr = self.history['learning_rates'][epoch]\n","\n","        print(f\"\\nEpoch {epoch+1}/{self.config.max_epochs} Summary:\")\n","        print(f\"Start Time: {epoch_start_str} | Duration: {epoch_time} | Total Elapsed: {total_time}\")\n","        print(f\"Learning Rate: {current_lr:.2e}\")\n","        print(f\"Train Loss: {self.history['train_loss'][-1]:.4f} | Val Loss: {val_metrics['loss']:.4f}\")\n","        print(f\"Train Acc: {train_metrics['accuracy']:.4f} | Val Acc: {val_metrics['accuracy']:.4f}\")\n","        print(f\"Train F1: {train_metrics['f1']:.4f} | Val F1: {val_metrics['f1']:.4f}\")\n","        print(f\"Train Precision: {train_metrics['precision']:.4f} | Val Precision: {val_metrics['precision']:.4f}\")\n","        print(f\"Train Recall: {train_metrics['recall']:.4f} | Val Recall: {val_metrics['recall']:.4f}\")\n","\n","    def _compute_epoch_metrics(self, data_loader: DataLoader, phase: str) -> Dict:\n","        \"\"\"Compute metrics for an entire epoch.\"\"\"\n","        self.model.eval() if phase == 'val' else self.model.train()\n","        metrics = {\n","            'loss': 0,\n","            'accuracy': 0,\n","            'f1': 0,\n","            'precision': 0,\n","            'recall': 0,\n","            'per_attribute': {\n","                i: {'tp': 0, 'fp': 0, 'fn': 0, 'tn': 0}\n","                for i in range(self.config.num_classes)\n","            }\n","        }\n","\n","        with torch.no_grad():\n","            for inputs, labels in data_loader:\n","                inputs, labels = inputs.to(self.device), labels.to(self.device)\n","                outputs = self.model(inputs)\n","\n","                # Calculate loss\n","                if phase == 'val':\n","                    metrics['loss'] += self.criterion(outputs, labels).item()\n","\n","                # Calculate predictions\n","                preds = (torch.sigmoid(outputs) > 0.5).float()\n","\n","                # Per-attribute metrics\n","                for attr in range(self.config.num_classes):\n","                    tp = ((preds[:, attr] == 1) & (labels[:, attr] == 1)).sum().item()\n","                    fp = ((preds[:, attr] == 1) & (labels[:, attr] == 0)).sum().item()\n","                    fn = ((preds[:, attr] == 0) & (labels[:, attr] == 1)).sum().item()\n","                    tn = ((preds[:, attr] == 0) & (labels[:, attr] == 0)).sum().item()\n","\n","                    metrics['per_attribute'][attr]['tp'] += tp\n","                    metrics['per_attribute'][attr]['fp'] += fp\n","                    metrics['per_attribute'][attr]['fn'] += fn\n","                    metrics['per_attribute'][attr]['tn'] += tn\n","\n","        # Aggregate metrics\n","        return self._aggregate_metrics(metrics, len(data_loader), phase)\n","\n","    def _aggregate_metrics(self, metrics: Dict, num_batches: int, phase: str) -> Dict:\n","        if phase == 'val':\n","            metrics['loss'] /= num_batches\n","\n","        attr_acc, attr_f1 = [], []\n","        attr_precision, attr_recall = [], []\n","\n","        for attr in range(self.config.num_classes):\n","            tp = metrics['per_attribute'][attr]['tp']\n","            fp = metrics['per_attribute'][attr]['fp']\n","            fn = metrics['per_attribute'][attr]['fn']\n","            tn = metrics['per_attribute'][attr]['tn']\n","\n","            acc = (tp + tn) / (tp + tn + fp + fn + 1e-9)\n","            precision = tp / (tp + fp + 1e-9)\n","            recall = tp / (tp + fn + 1e-9)\n","            f1 = 2 * (precision * recall) / (precision + recall + 1e-9)\n","\n","            self.history[f'{phase}_attr_metrics'][attr]['acc'].append(acc)\n","            self.history[f'{phase}_attr_metrics'][attr]['f1'].append(f1)\n","            self.history[f'{phase}_attr_metrics'][attr]['precision'].append(precision)\n","            self.history[f'{phase}_attr_metrics'][attr]['recall'].append(recall)\n","\n","            attr_acc.append(acc)\n","            attr_f1.append(f1)\n","            attr_precision.append(precision)\n","            attr_recall.append(recall)\n","\n","        metrics.update({\n","            'accuracy': np.mean(attr_acc),\n","            'f1': np.mean(attr_f1),\n","            'precision': np.mean(attr_precision),\n","            'recall': np.mean(attr_recall)\n","        })\n","\n","        self.history[f'{phase}_acc'].append(metrics['accuracy'])\n","        self.history[f'{phase}_f1'].append(metrics['f1'])\n","        self.history[f'{phase}_precision'].append(metrics['precision'])\n","        self.history[f'{phase}_recall'].append(metrics['recall'])\n","\n","        if phase == 'val':\n","            self.history['val_loss'].append(metrics['loss'])\n","        else:\n","            self.history['train_loss'].append(metrics['loss'])\n","\n","        return metrics\n","\n","    def _print_epoch_summary(self, epoch: int, train_metrics: Dict, val_metrics: Dict):\n","        print(f\"\\nEpoch {epoch+1} Summary:\")\n","        print(f\"Train Loss: {self.history['train_loss'][-1]:.4f} | Val Loss: {val_metrics['loss']:.4f}\")\n","        print(f\"Train Acc: {train_metrics['accuracy']:.4f} | Val Acc: {val_metrics['accuracy']:.4f}\")\n","        print(f\"Train F1: {train_metrics['f1']:.4f} | Val F1: {val_metrics['f1']:.4f}\")\n","\n","    def _print_final_metrics(self, val_loader: DataLoader):\n","        print(\"\\nFinal Validation Performance for All Attributes:\")\n","        print(f\"{'Attribute':<25} {'Accuracy':<8} {'F1':<8} {'Precision':<10} {'Recall':<10}\")\n","\n","        # Get final validation metrics\n","        final_metrics = {\n","            attr: {\n","                'acc': self.history['val_attr_metrics'][attr]['acc'][-1],\n","                'f1': self.history['val_attr_metrics'][attr]['f1'][-1],\n","                'precision': self.history['val_attr_metrics'][attr]['precision'][-1],\n","                'recall': self.history['val_attr_metrics'][attr]['recall'][-1]\n","            }\n","            for attr in range(self.config.num_classes)\n","        }\n","\n","        for attr in range(self.config.num_classes):\n","            print(f\"{self.config.attribute_names[attr]:<25} \"\n","                  f\"{final_metrics[attr]['acc']:.4f}    \"\n","                  f\"{final_metrics[attr]['f1']:.4f}    \"\n","                  f\"{final_metrics[attr]['precision']:.4f}      \"\n","                  f\"{final_metrics[attr]['recall']:.4f}\")\n","\n","# Usage Example\n","if __name__ == \"__main__\":\n","    config = Config()\n","    classifier = AttributeClassifier(config)\n","\n","    history = classifier.train(train_loader, val_loader)\n","    classifier.generate_visualizations()"]},{"cell_type":"code","execution_count":null,"id":"a44737d3-4406-44f5-97cd-2c86e544c3a0","metadata":{"id":"a44737d3-4406-44f5-97cd-2c86e544c3a0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"0604c58c-1851-4dc6-aab3-2c3a5247cc6b","metadata":{"id":"0604c58c-1851-4dc6-aab3-2c3a5247cc6b"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}