{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b3989b5-5d7a-43e6-9f03-43e50380293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Using device: cuda\n",
      "Training samples: 162770, Validation samples: 19867\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())  # If < 4, use fewer workers\n",
    "import torch.multiprocessing as mp\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Configuration (Your Code)\n",
    "# ========================\n",
    "class Config:\n",
    "    root_dir = 'C:/celeba/img_align_celeba/img_align_celeba'\n",
    "    csv_path = 'C:/celeba/list_attr_celeba.csv'\n",
    "    partition_csv_path = 'C:/celeba/list_eval_partition.csv'\n",
    "    num_classes = 40\n",
    "    batch_size = 32\n",
    "    lr = 1e-3\n",
    "    grad_accum_steps = 1\n",
    "    grad_clip = 1.0\n",
    "    max_epochs = 10\n",
    "    early_stop_patience = 5\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    attribute_names = [\n",
    "        '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes',\n",
    "        'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair',\n",
    "        'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin',\n",
    "        'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones',\n",
    "        'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',\n",
    "        'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks',\n",
    "        'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
    "        'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young'\n",
    "    ]\n",
    "\n",
    "# ======================\n",
    "# Dataset (Your Code)\n",
    "# ======================\n",
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, root_dir, csv_path, partition_csv_path, split, transform=None):\n",
    "        # Load attributes\n",
    "        self.df = pd.read_csv(csv_path).replace(-1, 0)\n",
    "        \n",
    "        # Load partition data\n",
    "        partition_df = pd.read_csv(partition_csv_path)\n",
    "        partition_df['partition'] = partition_df['partition'].astype(int)\n",
    "        \n",
    "        # Merge datasets\n",
    "        self.df = self.df.merge(partition_df, on='image_id', how='inner')\n",
    "        \n",
    "        # Convert split name to code\n",
    "        split_codes = {'train': 0, 'valid': 1, 'validation': 1, 'test': 2}\n",
    "        split = split.lower()\n",
    "        if split not in split_codes:\n",
    "            raise ValueError(f\"Invalid split: {split}. Use train/valid/test\")\n",
    "            \n",
    "        split_code = split_codes[split]\n",
    "        self.df = self.df[self.df['partition'] == split_code].copy()\n",
    "        \n",
    "        if len(self.df) == 0:\n",
    "            raise ValueError(f\"No samples found for {split} partition\")\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.labels = self.df.drop(['image_id', 'partition'], axis=1).values.astype('float32')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.df.iloc[idx]['image_id'])\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, self.labels[idx]\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError loading {img_path}: {str(e)}\")  # Keep only error reporting\n",
    "            raise\n",
    "\n",
    "# ========================\n",
    "# Initialize System\n",
    "# ========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Transforms (Your Code)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(Config.mean, Config.std)\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(Config.mean, Config.std)\n",
    "])\n",
    "\n",
    "# Create datasets (Your Code)\n",
    "try:\n",
    "    train_set = CelebADataset(\n",
    "        root_dir=Config.root_dir,\n",
    "        csv_path=Config.csv_path,\n",
    "        partition_csv_path=Config.partition_csv_path,\n",
    "        split='train',\n",
    "        transform=train_transform\n",
    "    )\n",
    "\n",
    "    val_set = CelebADataset(\n",
    "        root_dir=Config.root_dir,\n",
    "        csv_path=Config.csv_path,\n",
    "        partition_csv_path=Config.partition_csv_path,\n",
    "        split='valid',\n",
    "        transform=eval_transform\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error creating dataset: {str(e)}\")\n",
    "    raise\n",
    "mp.set_start_method(\"spawn\", force=True)\n",
    "# Data loaders (Your Code)\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "# Replace your train_loader with:\n",
    "# train_loader = DataLoader(\n",
    "#     torch.utils.data.Subset(train_set, range(64)),  # 1 batch only\n",
    "#     batch_size=32,\n",
    "#     num_workers=2,\n",
    "#     persistent_workers=True\n",
    "# )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_set)}, Validation samples: {len(val_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44084499-fed5-412c-8cff-87fa14aad3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA synchronized\n",
      "First image loaded successfully: torch.Size([3, 224, 224])\n",
      "First batch loaded: torch.Size([32, 3, 224, 224])\n",
      "Warmup completed\n",
      "Sample batch shape: torch.Size([32, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_21720\\1388561182.py:93: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_soft = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_21720\\1388561182.py:94: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_attention = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy output shape: torch.Size([2, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]:   0%|                    | 0/5087 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch input shape: torch.Size([32, 3, 224, 224])\n",
      "First batch loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_21720\\1388561182.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():  # Add this context manager\n",
      "Epoch 1/10 [Train]: 100%|████████████████████| 5087/5087 [46:06<00:00,  1.84it/s, soft=1.1064, attention=1.1155]\n",
      "Epoch 1/10 [Val]: 100%|███████████████████████████████| 621/621 [04:58<00:00,  2.08it/s, soft=0.0903, attention=0.0914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary:\n",
      "Train Losses => Soft: 1.1064 | Attention: 1.1155\n",
      "Val Losses   => Soft: 0.7396 | Attention: 0.7490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|████████████████████| 5087/5087 [30:33<00:00,  2.78it/s, soft=1.1064, attention=1.1155]\n",
      "Epoch 2/10 [Val]: 100%|███████████████████████████████| 621/621 [02:22<00:00,  4.37it/s, soft=0.0898, attention=0.0911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Summary:\n",
      "Train Losses => Soft: 1.1064 | Attention: 1.1155\n",
      "Val Losses   => Soft: 0.7358 | Attention: 0.7462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|████████████████████| 5087/5087 [30:34<00:00,  2.77it/s, soft=1.1064, attention=1.1155]\n",
      "Epoch 3/10 [Val]: 100%|███████████████████████████████| 621/621 [02:22<00:00,  4.35it/s, soft=0.0898, attention=0.0912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Summary:\n",
      "Train Losses => Soft: 1.1064 | Attention: 1.1155\n",
      "Val Losses   => Soft: 0.7356 | Attention: 0.7467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|████████████████████| 5087/5087 [30:32<00:00,  2.78it/s, soft=1.1064, attention=1.1155]\n",
      "Epoch 4/10 [Val]: 100%|███████████████████████████████| 621/621 [02:21<00:00,  4.38it/s, soft=0.0895, attention=0.0912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Summary:\n",
      "Train Losses => Soft: 1.1064 | Attention: 1.1155\n",
      "Val Losses   => Soft: 0.7335 | Attention: 0.7467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|████████████████████| 5087/5087 [30:31<00:00,  2.78it/s, soft=1.1064, attention=1.1155]\n",
      "Epoch 5/10 [Val]: 100%|███████████████████████████████| 621/621 [02:22<00:00,  4.36it/s, soft=0.0896, attention=0.0910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Summary:\n",
      "Train Losses => Soft: 1.1064 | Attention: 1.1155\n",
      "Val Losses   => Soft: 0.7340 | Attention: 0.7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|████████████████████| 5087/5087 [30:34<00:00,  2.77it/s, soft=1.1064, attention=1.1155]\n",
      "Epoch 6/10 [Val]: 100%|███████████████████████████████| 621/621 [02:22<00:00,  4.36it/s, soft=0.0897, attention=0.0910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Summary:\n",
      "Train Losses => Soft: 1.1064 | Attention: 1.1155\n",
      "Val Losses   => Soft: 0.7351 | Attention: 0.7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|████████████████████| 5087/5087 [30:33<00:00,  2.77it/s, soft=1.1064, attention=1.1155]\n",
      "Epoch 7/10 [Val]: 100%|███████████████████████████████| 621/621 [02:22<00:00,  4.35it/s, soft=0.0896, attention=0.0910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 Summary:\n",
      "Train Losses => Soft: 1.1064 | Attention: 1.1155\n",
      "Val Losses   => Soft: 0.7337 | Attention: 0.7455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|████████████████████| 5087/5087 [30:36<00:00,  2.77it/s, soft=1.1064, attention=1.1155]\n",
      "Epoch 8/10 [Val]: 100%|███████████████████████████████| 621/621 [02:22<00:00,  4.37it/s, soft=0.0901, attention=0.0913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 Summary:\n",
      "Train Losses => Soft: 1.1064 | Attention: 1.1155\n",
      "Val Losses   => Soft: 0.7378 | Attention: 0.7479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|████████████████████| 5087/5087 [30:35<00:00,  2.77it/s, soft=1.1064, attention=1.1155]\n",
      "Epoch 9/10 [Val]: 100%|███████████████████████████████| 621/621 [02:23<00:00,  4.34it/s, soft=0.0898, attention=0.0911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 Summary:\n",
      "Train Losses => Soft: 1.1064 | Attention: 1.1155\n",
      "Val Losses   => Soft: 0.7353 | Attention: 0.7460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|████████████████████| 5087/5087 [30:36<00:00,  2.77it/s, soft=1.1064, attention=1.1155]\n",
      "Epoch 10/10 [Val]: 100%|██████████████████████████████| 621/621 [02:22<00:00,  4.35it/s, soft=0.0896, attention=0.0910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 Summary:\n",
      "Train Losses => Soft: 1.1064 | Attention: 1.1155\n",
      "Val Losses   => Soft: 0.7341 | Attention: 0.7455\n",
      "\n",
      "Early stopping triggered after 5 epochs without improvement\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# DML Training Setup\n",
    "# ========================\n",
    "# Load your pre-trained models (MODIFY PATHS AS NEEDED)\n",
    "# model_soft = torch.load('C:/Users/akash/Downloads/Soft.pth').to(device)\n",
    "# model_attention = torch.load('C:/Users/akash/Downloads/AT.pth').to(device)\n",
    "\n",
    "# Initialize models\n",
    "# model_soft = models.resnet50(pretrained=False).to(device)\n",
    "# model_attention = models.resnet50(pretrained=False).to(device)\n",
    "\n",
    "# # Modify final layer for CelebA's 40 classes\n",
    "# model_soft.fc = torch.nn.Linear(512, Config.num_classes).to(device)\n",
    "# model_attention.fc = torch.nn.Linear(512, Config.num_classes).to(device)\n",
    "\n",
    "# # Load weights\n",
    "# model_soft.load_state_dict(torch.load('C:/Users/akash/Downloads/Soft.pth'), map_location=device, strict=False)\n",
    "# model_attention.load_state_dict(torch.load('C:/Users/akash/Downloads/AT.pth'),map_location=device, strict=False)\n",
    "# ========================\n",
    "# DML Training Setup (Corrected)\n",
    "# ========================\n",
    "\n",
    "# Ensure CUDA operations complete\n",
    "torch.cuda.synchronize(device)\n",
    "print(\"CUDA synchronized\")\n",
    "\n",
    "# Test single image load\n",
    "test_img, test_label = train_set[0]\n",
    "print(\"First image loaded successfully:\", test_img.shape)\n",
    "\n",
    "# Test single batch\n",
    "test_batch = next(iter(train_loader))\n",
    "print(\"First batch loaded:\", test_batch[0].shape)\n",
    "\n",
    "# Initialize models\n",
    "model_soft = models.resnet50(weights=None).to(device)\n",
    "model_attention = models.resnet50(weights=None).to(device)\n",
    "\n",
    "# Modify final layer for CelebA's 40 classes (should be 2048 input features for ResNet-50)\n",
    "model_soft.fc = torch.nn.Linear(2048, Config.num_classes).to(device)  # Fixed input size\n",
    "model_attention.fc = torch.nn.Linear(2048, Config.num_classes).to(device)  # Fixed input size\n",
    "\n",
    "# Load weights CORRECTLY\n",
    "model_soft.load_state_dict(\n",
    "    torch.load('C:/Users/akash/Downloads/Soft.pth', map_location=device),  # Move map_location here\n",
    "    strict=False\n",
    ")\n",
    "model_attention.load_state_dict(\n",
    "    torch.load('C:/Users/akash/Downloads/AT.pth', map_location=device),  # Move map_location here\n",
    "    strict=False\n",
    ")\n",
    "\n",
    "# # Initialize the student model (ResNet-18)\n",
    "# student_model = models.resnet18(pretrained=True)\n",
    "# student_model.load_state_dict(torch.load(\"/content/drive/MyDrive/KnowledgeDistillation/celebA/models/student_model_at_best_reduced.pth\", map_location=torch.device('cpu')), strict=False)  # Load your trained weights\n",
    "# student_model.fc = torch.nn.Linear(512, num_classes) \n",
    "\n",
    "# Initialize optimizers\n",
    "optimizer_soft = torch.optim.Adam(model_soft.parameters(), lr=Config.lr)\n",
    "optimizer_attention = torch.optim.Adam(model_attention.parameters(), lr=Config.lr)\n",
    "\n",
    "\n",
    "\n",
    "# Loss functions\n",
    "criterion_bce = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "lambda_mutual = 0.5\n",
    "\n",
    "def mutual_loss(output1, output2):\n",
    "    prob1 = torch.sigmoid(output1)\n",
    "    prob2 = torch.sigmoid(output2.detach())\n",
    "    return torch.nn.BCELoss()(prob1, prob2)\n",
    "\n",
    "# ========================\n",
    "# Enhanced Training Loop\n",
    "# ========================\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "_ = model_soft(dummy_input)  # Compile CUDA kernels\n",
    "print(\"Warmup completed\")  # Verify execution\n",
    "\n",
    "# Test dataset access\n",
    "test_sample = next(iter(train_loader))\n",
    "print(\"Sample batch shape:\", test_sample[0].shape)  # Should show (batch_size, 3, 224, 224)\n",
    "\n",
    "# Test model forward pass\n",
    "dummy_input = torch.randn(2, 3, 224, 224).to(device)\n",
    "with torch.no_grad():\n",
    "    output = model_soft(dummy_input)\n",
    "print(\"Dummy output shape:\", output.shape)  # Should be (2, 40)\n",
    "\n",
    "scaler_soft = torch.cuda.amp.GradScaler()\n",
    "scaler_attention = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "for epoch in range(Config.max_epochs):\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    # Training Phase\n",
    "    model_soft.train()\n",
    "    model_attention.train()\n",
    "    epoch_train_loss = {'soft': 0.0, 'attention': 0.0}\n",
    "    \n",
    "    progress = tqdm(train_loader, \n",
    "                desc=f\"Epoch {epoch+1}/{Config.max_epochs} [Train]\",\n",
    "                bar_format=\"{l_bar}{bar:20}{r_bar}\",\n",
    "                disable=False)  # Disable for cleaner output if needed\n",
    "    for batch_idx, (images, targets) in enumerate(progress):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "\n",
    "        # Add before forward pass\n",
    "        if batch_idx == 0 and epoch == 0:\n",
    "            print(\"First batch input shape:\", images.shape)\n",
    "            print(\"First batch loaded successfully\")\n",
    "        \n",
    "        # Forward passes\n",
    "        # out_soft = model_soft(images)\n",
    "        # out_attention = model_attention(images)\n",
    "\n",
    "        with torch.cuda.amp.autocast():  # Add this context manager\n",
    "        # Forward passes\n",
    "            out_soft = model_soft(images)\n",
    "            out_attention = model_attention(images)\n",
    "        \n",
    "        # Calculate losses\n",
    "        task_loss_soft = criterion_bce(out_soft, targets)\n",
    "        task_loss_attention = criterion_bce(out_attention, targets)\n",
    "        \n",
    "        mutual_loss_soft = mutual_loss(out_soft, out_attention)\n",
    "        mutual_loss_attention = mutual_loss(out_attention, out_soft)\n",
    "        \n",
    "        total_loss_soft = task_loss_soft + lambda_mutual * mutual_loss_soft\n",
    "        total_loss_attention = task_loss_attention + lambda_mutual * mutual_loss_attention\n",
    "        \n",
    "        # Gradient accumulation\n",
    "        total_loss_soft = total_loss_soft / Config.grad_accum_steps\n",
    "        total_loss_attention = total_loss_attention / Config.grad_accum_steps\n",
    "        \n",
    "        # total_loss_soft.backward()\n",
    "        # total_loss_attention.backward()\n",
    "\n",
    "        scaler_soft.scale(total_loss_soft).backward()\n",
    "        scaler_attention.scale(total_loss_attention).backward()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Gradient handling\n",
    "        if (batch_idx + 1) % Config.grad_accum_steps == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model_soft.parameters(), Config.grad_clip)\n",
    "            torch.nn.utils.clip_grad_norm_(model_attention.parameters(), Config.grad_clip)\n",
    "            \n",
    "            # optimizer_soft.step()\n",
    "            # optimizer_attention.step()\n",
    "            \n",
    "            # optimizer_soft.zero_grad()\n",
    "            # optimizer_attention.zero_grad()\n",
    "\n",
    "            scaler_soft.step(optimizer_soft)\n",
    "            scaler_attention.step(optimizer_attention)\n",
    "            scaler_soft.update()\n",
    "            scaler_attention.update()\n",
    "\n",
    "            # Inside your training loop, after optimizer steps\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Update metrics\n",
    "        epoch_train_loss['soft'] += total_loss_soft.item() * Config.grad_accum_steps\n",
    "        epoch_train_loss['attention'] += total_loss_attention.item() * Config.grad_accum_steps\n",
    "        \n",
    "        progress.set_postfix({\n",
    "            'soft': f\"{epoch_train_loss['soft']/(batch_idx+1):.4f}\",\n",
    "            'attention': f\"{epoch_train_loss['attention']/(batch_idx+1):.4f}\"\n",
    "        })\n",
    "    \n",
    "    # Validation Phase\n",
    "    model_soft.eval()\n",
    "    model_attention.eval()\n",
    "    val_loss = {'soft': 0.0, 'attention': 0.0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_progress = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{Config.max_epochs} [Val]\")\n",
    "        for images, targets in val_progress:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            out_soft = model_soft(images)\n",
    "            out_attention = model_attention(images)\n",
    "            \n",
    "            val_loss['soft'] += criterion_bce(out_soft, targets).item()\n",
    "            val_loss['attention'] += criterion_bce(out_attention, targets).item()\n",
    "            \n",
    "            val_progress.set_postfix({\n",
    "                'soft': f\"{val_loss['soft']/(batch_idx+1):.4f}\",\n",
    "                'attention': f\"{val_loss['attention']/(batch_idx+1):.4f}\"\n",
    "            })\n",
    "    \n",
    "    # Calculate epoch metrics\n",
    "    avg_train_soft = epoch_train_loss['soft'] / len(train_loader)\n",
    "    avg_train_attention = epoch_train_loss['attention'] / len(train_loader)\n",
    "    avg_val_soft = val_loss['soft'] / len(val_loader)\n",
    "    avg_val_attention = val_loss['attention'] / len(val_loader)\n",
    "    avg_val_loss = (avg_val_soft + avg_val_attention) / 2\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    print(f\"Train Losses => Soft: {avg_train_soft:.4f} | Attention: {avg_train_attention:.4f}\")\n",
    "    print(f\"Val Losses   => Soft: {avg_val_soft:.4f} | Attention: {avg_val_attention:.4f}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model_soft.state_dict(), \"best_soft_model.pth\")\n",
    "        torch.save(model_attention.state_dict(), \"best_attention_model.pth\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= Config.early_stop_patience:\n",
    "            print(f\"\\nEarly stopping triggered after {Config.early_stop_patience} epochs without improvement\")\n",
    "            break\n",
    "\n",
    "# Final save\n",
    "torch.save(model_soft.state_dict(), \"final_soft_model.pth\")\n",
    "torch.save(model_attention.state_dict(), \"final_attention_model.pth\")\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e16b7ef6-d7e6-42a7-a945-e7a83e9dbd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA synchronized\n",
      "First image loaded successfully: torch.Size([3, 224, 224])\n",
      "First batch loaded: torch.Size([32, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_25328\\2159831454.py:48: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "Epoch 1/10:   0%|                                                                             | 0/5087 [00:00<?, ?it/s]C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_25328\\2159831454.py:65: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 1/10: 100%|███████████████████████████| 5087/5087 [33:41<00:00,  2.52it/s, task_loss=0.3715, mutual_loss=-0.1627]\n",
      "Epoch 2/10: 100%|███████████████████████████| 5087/5087 [28:50<00:00,  2.94it/s, task_loss=0.3307, mutual_loss=-0.1653]\n",
      "Epoch 3/10: 100%|███████████████████████████| 5087/5087 [28:49<00:00,  2.94it/s, task_loss=0.3423, mutual_loss=-0.1700]\n",
      "Epoch 4/10: 100%|███████████████████████████| 5087/5087 [28:51<00:00,  2.94it/s, task_loss=0.3363, mutual_loss=-0.1672]\n",
      "Epoch 5/10: 100%|███████████████████████████| 5087/5087 [28:49<00:00,  2.94it/s, task_loss=0.3839, mutual_loss=-0.1677]\n",
      "Epoch 6/10: 100%|███████████████████████████| 5087/5087 [28:52<00:00,  2.94it/s, task_loss=0.3834, mutual_loss=-0.1625]\n",
      "Epoch 7/10: 100%|███████████████████████████| 5087/5087 [36:28<00:00,  2.32it/s, task_loss=0.3114, mutual_loss=-0.1715]\n",
      "Epoch 8/10: 100%|███████████████████████████| 5087/5087 [40:14<00:00,  2.11it/s, task_loss=0.3158, mutual_loss=-0.1699]\n",
      "Epoch 9/10: 100%|███████████████████████████| 5087/5087 [28:59<00:00,  2.92it/s, task_loss=0.3235, mutual_loss=-0.1722]\n",
      "Epoch 10/10: 100%|██████████████████████████| 5087/5087 [28:57<00:00,  2.93it/s, task_loss=0.2922, mutual_loss=-0.1734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# ========================\n",
    "# DML Training Setup (Corrected)\n",
    "# ========================\n",
    "\n",
    "# Ensure CUDA operations complete\n",
    "torch.cuda.synchronize(device)\n",
    "print(\"CUDA synchronized\")\n",
    "\n",
    "# Test single image load\n",
    "test_img, test_label = train_set[0]\n",
    "print(\"First image loaded successfully:\", test_img.shape)\n",
    "\n",
    "# Test single batch\n",
    "test_batch = next(iter(train_loader))\n",
    "print(\"First batch loaded:\", test_batch[0].shape)\n",
    "\n",
    "# Initialize models\n",
    "model_soft = models.resnet50(weights=None).to(device)\n",
    "model_attention = models.resnet50(weights=None).to(device)\n",
    "\n",
    "# Modify final layer for CelebA's 40 classes (should be 2048 input features for ResNet-50)\n",
    "model_soft.fc = torch.nn.Linear(2048, Config.num_classes).to(device)  # Fixed input size\n",
    "model_attention.fc = torch.nn.Linear(2048, Config.num_classes).to(device)  # Fixed input size\n",
    "\n",
    "# Load weights CORRECTLY\n",
    "model_soft.load_state_dict(\n",
    "    torch.load('C:/Users/akash/Downloads/Soft.pth', map_location=device),  # Move map_location here\n",
    "    strict=False\n",
    ")\n",
    "model_attention.load_state_dict(\n",
    "    torch.load('C:/Users/akash/Downloads/AT.pth', map_location=device),  # Move map_location here\n",
    "    strict=False\n",
    ")\n",
    "\n",
    "optimizer_soft = optim.AdamW(model_soft.parameters(), lr=Config.lr, weight_decay=0.05)\n",
    "optimizer_attention = optim.AdamW(model_attention.parameters(), lr=Config.lr, weight_decay=0.05)\n",
    "\n",
    "pos_weights = torch.ones(Config.num_classes).to(device) * 1.2\n",
    "criterion_bce = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "\n",
    "def enhanced_mutual_loss(out1, out2):\n",
    "    kl_loss = F.kl_div(F.log_softmax(out1, dim=1), F.softmax(out2.detach(), dim=1), reduction='batchmean')\n",
    "    cos_loss = -F.cosine_similarity(out1, out2.detach()).mean()\n",
    "    return kl_loss + 0.3 * cos_loss\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# ========================\n",
    "# Training Loop\n",
    "# ========================\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(Config.max_epochs):\n",
    "    model_soft.train()\n",
    "    model_attention.train()\n",
    "    epoch_loss = {'soft': 0.0, 'attn': 0.0}\n",
    "    \n",
    "    progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Config.max_epochs}\")\n",
    "    for batch_idx, (images, targets) in enumerate(progress):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            out_soft = model_soft(images)\n",
    "            out_attn = model_attention(images)\n",
    "            \n",
    "            task_loss = 0.7 * (criterion_bce(out_soft, targets) + criterion_bce(out_attn, targets))\n",
    "            mutual_loss = 0.3 * (enhanced_mutual_loss(out_soft, out_attn) + enhanced_mutual_loss(out_attn, out_soft))\n",
    "            total_loss = task_loss + mutual_loss\n",
    "        \n",
    "        scaler.scale(total_loss).backward()\n",
    "        \n",
    "        if (batch_idx + 1) % Config.grad_accum_steps == 0:\n",
    "            scaler.unscale_(optimizer_soft)\n",
    "            scaler.unscale_(optimizer_attention)\n",
    "            torch.nn.utils.clip_grad_norm_(model_soft.parameters(), Config.grad_clip)\n",
    "            torch.nn.utils.clip_grad_norm_(model_attention.parameters(), Config.grad_clip)\n",
    "            scaler.step(optimizer_soft)\n",
    "            scaler.step(optimizer_attention)\n",
    "            scaler.update()\n",
    "            optimizer_soft.zero_grad(set_to_none=True)\n",
    "            optimizer_attention.zero_grad(set_to_none=True)\n",
    "        \n",
    "        epoch_loss['soft'] += total_loss.item()\n",
    "        progress.set_postfix({'task_loss': f\"{task_loss.item():.4f}\", 'mutual_loss': f\"{mutual_loss.item():.4f}\"})\n",
    "    \n",
    "    epoch_loss['soft'] /= len(train_loader)\n",
    "    \n",
    "    model_soft.eval()\n",
    "    model_attention.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            val_loss += criterion_bce(model_soft(images), targets).item()\n",
    "            val_loss += criterion_bce(model_attention(images), targets).item()\n",
    "    avg_val_loss = val_loss / (2 * len(val_loader))\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model_soft.state_dict(), \"best_model_soft.pth\")\n",
    "        torch.save(model_attention.state_dict(), \"best_model_attention.pth\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= Config.early_stop_patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adeb70f8-b2cf-4e71-92ad-02ad3392e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_set, Config.batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, Config.batch_size, pin_memory=True)\n",
    "# Optimized Model Class\n",
    "class AttributeClassifier:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = models.resnet50(weights=None)\n",
    "        \n",
    "        # Freeze layers\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.model.layer3.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        # Modified head\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, config.num_classes)\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # Optimizer\n",
    "        self.optimizer = optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, self.model.parameters()),\n",
    "            lr=config.lr,\n",
    "            weight_decay=0.01\n",
    "        )\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def train(self, train_loader, val_loader):\n",
    "        best_f1 = 0\n",
    "        epochs_no_improve = 0\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        for epoch in range(self.config.max_epochs):\n",
    "            # Training phase\n",
    "            self.model.train()\n",
    "            epoch_train_loss = 0.0\n",
    "            \n",
    "            for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "                inputs = inputs.to(self.device, non_blocking=True)\n",
    "                labels = labels.to(self.device, non_blocking=True)\n",
    "                \n",
    "                # Mixed precision forward pass\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = self.model(inputs)\n",
    "                    loss = self.criterion(outputs, labels) / self.config.grad_accum_steps\n",
    "                \n",
    "                # Backward pass with gradient scaling\n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                # Gradient accumulation steps\n",
    "                if (batch_idx + 1) % self.config.grad_accum_steps == 0:\n",
    "                    # Unscale before clipping\n",
    "                    scaler.unscale_(self.optimizer)\n",
    "                    \n",
    "                    # Gradient clipping\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        self.model.parameters(),\n",
    "                        self.config.grad_clip\n",
    "                    )\n",
    "                    \n",
    "                    # Optimizer step\n",
    "                    scaler.step(self.optimizer)\n",
    "                    scaler.update()\n",
    "                    self.optimizer.zero_grad(set_to_none=True)\n",
    "                \n",
    "                epoch_train_loss += loss.item() * self.config.grad_accum_steps\n",
    "            \n",
    "            # Calculate average training loss\n",
    "            avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "            \n",
    "            # Validation phase\n",
    "            avg_val_loss, avg_f1 = self._validate(val_loader)\n",
    "            \n",
    "            # Early stopping logic\n",
    "            if avg_f1 > best_f1:\n",
    "                best_f1 = avg_f1\n",
    "                epochs_no_improve = 0\n",
    "                torch.save(self.model.state_dict(), 'best_model.pth')\n",
    "                print(f\"Epoch {epoch+1}/{self.config.max_epochs}\")\n",
    "                print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "                print(f\"Val F1: {avg_f1:.4f}* (Best)\")\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                print(f\"Epoch {epoch+1}/{self.config.max_epochs}\")\n",
    "                print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "                print(f\"Val F1: {avg_f1:.4f} (No improvement {epochs_no_improve}/{self.config.early_stop_patience})\")\n",
    "            \n",
    "            if epochs_no_improve >= self.config.early_stop_patience:\n",
    "                print(f\"\\nEarly stopping triggered after {epoch+1} epochs!\")\n",
    "                break\n",
    "    \n",
    "        # Load best model weights\n",
    "        self.model.load_state_dict(torch.load('best_model.pth'))\n",
    "        print(\"Training complete. Loaded best model weights.\")\n",
    "\n",
    "    def _validate(self, val_loader):\n",
    "        self.model.eval()\n",
    "        val_loss = 0.0\n",
    "        total_f1 = 0.0\n",
    "        \n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device).float()\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                # Calculate loss\n",
    "                val_loss += self.criterion(outputs, labels).item()\n",
    "                \n",
    "                # Calculate F1\n",
    "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                total_f1 += self._calculate_f1(preds, labels)\n",
    "    \n",
    "        return val_loss/len(val_loader), total_f1/len(val_loader)\n",
    "\n",
    "\n",
    "\n",
    "    def _calculate_f1(self, preds, labels):\n",
    "            # Convert boolean masks to float for calculations\n",
    "        preds = preds.bool()\n",
    "        labels = labels.bool()\n",
    "            \n",
    "        tp = (preds & labels).sum(0, dtype=torch.float32)\n",
    "        fp = (preds & ~labels).sum(0, dtype=torch.float32)\n",
    "        fn = (~preds & labels).sum(0, dtype=torch.float32)\n",
    "            \n",
    "        precision = tp / (tp + fp + 1e-9)\n",
    "        recall = tp / (tp + fn + 1e-9)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
    "        return f1.mean().item()\n",
    "        \n",
    "    def test(self, test_loader, top_ks=[5, 10, 20, 30]):\n",
    "        self.model.eval()\n",
    "        results = {\n",
    "            'strict': 0.0,\n",
    "            'mean': 0.0,\n",
    "            'top_acc': {k: 0.0 for k in top_ks},\n",
    "            'per_attribute': {}\n",
    "        }\n",
    "        attr_correct = torch.zeros(self.config.num_classes).to(self.device)\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad(), torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                batch_size = inputs.size(0)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                preds = (probs > 0.5).float()\n",
    "                \n",
    "                # Per-image metrics\n",
    "                results['strict'] += (preds == labels).all(dim=1).sum().item()\n",
    "                results['mean'] += (preds == labels).float().mean(dim=1).sum().item()\n",
    "                \n",
    "                # Per-attribute metrics\n",
    "                attr_correct += (preds == labels).sum(dim=0)\n",
    "                \n",
    "                # Top-k calculations\n",
    "                for k in top_ks:\n",
    "                    topk_probs, topk_indices = torch.topk(probs, k, dim=1)\n",
    "                    correct = torch.gather(labels, 1, topk_indices).sum(dim=1)\n",
    "                    results['top_acc'][k] += (correct.float() / k).sum().item()\n",
    "                \n",
    "                total_samples += batch_size\n",
    "    \n",
    "        # Calculate final metrics\n",
    "        results['strict'] /= total_samples\n",
    "        results['mean'] /= total_samples\n",
    "        for k in top_ks:\n",
    "            results['top_acc'][k] /= total_samples\n",
    "        \n",
    "        # Per-attribute accuracies\n",
    "        per_attr_acc = (attr_correct / total_samples).cpu().numpy()\n",
    "        for idx, acc in enumerate(per_attr_acc):\n",
    "            results['per_attribute'][self.config.attribute_names[idx]] = acc\n",
    "    \n",
    "        # Print results\n",
    "        print(\"\\n=== Test Results ===\")\n",
    "        print(f\"Strict Accuracy: {results['strict']:.4f}\")\n",
    "        print(f\"Mean Accuracy: {results['mean']:.4f}\")\n",
    "        for k in sorted(top_ks):\n",
    "            print(f\"Top-{k} Accuracy: {results['top_acc'][k]:.4f}\")\n",
    "        \n",
    "        # Print per-attribute accuracies\n",
    "        # Inside the test() method, replace the print block with:\n",
    "        print(\"\\nPer-Attribute Accuracy Ranking:\")\n",
    "        print(\"-\" * 65)\n",
    "        print(f\"{'Rank':<5}{'Attribute':<30}{'Accuracy':<10} | {'Rank':<5}{'Attribute':<30}{'Accuracy':<10}\")\n",
    "        print(\"-\" * 65)\n",
    "        \n",
    "        sorted_attrs = sorted(results['per_attribute'].items(), key=lambda x: x[1], reverse=True)\n",
    "        for i in range(0, len(sorted_attrs), 2):\n",
    "            line = \"\"\n",
    "            # First column\n",
    "            if i < len(sorted_attrs):\n",
    "                name, acc = sorted_attrs[i]\n",
    "                line += f\"{i+1:<5}{name:<30}{acc:.4f}    \"\n",
    "            else:\n",
    "                line += \" \" * 45\n",
    "                \n",
    "            # Second column\n",
    "            line += \"| \"\n",
    "            if i+1 < len(sorted_attrs):\n",
    "                name, acc = sorted_attrs[i+1]\n",
    "                line += f\"{i+2:<5}{name:<30}{acc:.4f}\"\n",
    "            \n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8c6b687-62e1-4b13-a21a-d20580010424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Results ===\n",
      "Strict Accuracy: 0.0165\n",
      "Mean Accuracy: 0.9058\n",
      "Top-5 Accuracy: 0.9044\n",
      "Top-10 Accuracy: 0.7329\n",
      "Top-20 Accuracy: 0.4574\n",
      "Top-30 Accuracy: 0.3083\n",
      "\n",
      "Per-Attribute Accuracy Ranking:\n",
      "-----------------------------------------------------------------\n",
      "Rank Attribute                     Accuracy   | Rank Attribute                     Accuracy  \n",
      "-----------------------------------------------------------------\n",
      "1    Eyeglasses                    0.9961    | 2    Wearing_Hat                   0.9908\n",
      "3    Bald                          0.9889    | 4    Gray_Hair                     0.9828\n",
      "5    Male                          0.9765    | 6    Pale_Skin                     0.9712\n",
      "7    Mustache                      0.9680    | 8    Goatee                        0.9665\n",
      "9    Sideburns                     0.9661    | 10   No_Beard                      0.9617\n",
      "11   Double_Chin                   0.9616    | 12   Blurry                        0.9598\n",
      "13   Bangs                         0.9596    | 14   Chubby                        0.9548\n",
      "15   Wearing_Necktie               0.9528    | 16   Blond_Hair                    0.9507\n",
      "17   Wearing_Lipstick              0.9441    | 18   Rosy_Cheeks                   0.9391\n",
      "19   Mouth_Slightly_Open           0.9376    | 20   5_o_Clock_Shadow              0.9361\n",
      "21   Receding_Hairline             0.9326    | 22   Bushy_Eyebrows                0.9281\n",
      "23   Smiling                       0.9196    | 24   Heavy_Makeup                  0.9074\n",
      "25   Wearing_Earrings              0.8935    | 26   Black_Hair                    0.8816\n",
      "27   Narrow_Eyes                   0.8712    | 28   Young                         0.8712\n",
      "29   Wearing_Necklace              0.8645    | 30   Brown_Hair                    0.8587\n",
      "31   High_Cheekbones               0.8577    | 32   Bags_Under_Eyes               0.8485\n",
      "33   Wavy_Hair                     0.8291    | 34   Arched_Eyebrows               0.8289\n",
      "35   Big_Nose                      0.8245    | 36   Straight_Hair                 0.8240\n",
      "37   Attractive                    0.8152    | 38   Pointy_Nose                   0.7571\n",
      "39   Oval_Face                     0.7455    | 40   Big_Lips                      0.7086\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m classifier\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_attention.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Run evaluation\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m strict_acc, mean_acc \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mtest(test_loader)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    config = Config()\n",
    "    \n",
    "    # Create test dataset\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(config.mean, config.std)\n",
    "    ])\n",
    "    \n",
    "    test_set = CelebADataset(\n",
    "        root_dir=config.root_dir,\n",
    "        csv_path=config.csv_path,\n",
    "        partition_csv_path=config.partition_csv_path,\n",
    "        split='test',\n",
    "        transform=test_transform\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_set,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Initialize and load model\n",
    "    classifier = AttributeClassifier(config)\n",
    "    classifier.model.load_state_dict(torch.load('best_model_attention.pth'))\n",
    "    \n",
    "    # Run evaluation\n",
    "    strict_acc, mean_acc = classifier.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d9635-2abc-4353-ac0c-b5977ee3b4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
